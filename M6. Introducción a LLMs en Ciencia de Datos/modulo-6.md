# MÃ³dulo 6: IntroducciÃ³n a Modelos de Lenguaje en Ciencia de Datos

**DuraciÃ³n total:** 6 horas lectivas + 3 horas de trabajo autÃ³nomo  
**Objetivo general:** Aprender a utilizar modelos de lenguaje (LLMs) para consultar, analizar e interpretar datos mediante lenguaje natural, integrÃ¡ndolos con herramientas de ciencia de datos como Pandas y visualizaciÃ³n automÃ¡tica.

---

## ğŸ“… SesiÃ³n 1 (3h): IntroducciÃ³n al uso de LLMs para anÃ¡lisis de datos

### Parte teÃ³rica (30 min)

- Â¿QuÃ© es un LLM y cÃ³mo se relaciona con la ciencia de datos?
- IntroducciÃ³n a la arquitectura **Transformer** (explicaciÃ³n + grÃ¡fico).
- Casos de uso de LLMs para anÃ¡lisis de datos.
- Â¿QuÃ© es un *prompt* y cÃ³mo influye en los resultados?
- Buenas prÃ¡cticas para redactar instrucciones claras a un modelo.

ğŸ“ Recursos:
- [ChatGPT (OpenAI)](https://chat.openai.com/)
- [Gemini (Google)](https://gemini.google.com/)
- [Prompt Engineering Guide](https://platform.openai.com/docs/guides/gpt-best-practices)

---

### Ejercicios prÃ¡cticos

1. **Ejercicio 1 â€“ Buenas prÃ¡cticas con prompts**  
   Comparativa entre prompts vagos y precisos. ExploraciÃ³n de un dataset con consumo energÃ©tico (`consumo_diario.csv`).

2. **Ejercicio 2 â€“ AnÃ¡lisis exploratorio automÃ¡tico con un modelo de lenguaje**  
   Usar lenguaje natural para describir y graficar datos directamente con un LLM.

3. **Ejercicio 3 - GeneraciÃ³n de cÃ³digo con un LLM**
   Aprender a utilizar un modelo de lenguaje para generar cÃ³digo Python que permita analizar datos

4. **Ejercicio 4 â€“ DetecciÃ³n de anomalÃ­as en series temporales**  
   Uso de LLM para detectar consumos anÃ³malos (outliers) en una serie temporal y generar visualizaciones marcando esos valores.

### Agenda de la sesiÃ³n 1

| Tiempo estimado | Actividad | Contenido | Herramientas |
|-----------------|-----------|-----------|--------------|
| **0:00 - 0:30** | ğŸ§  **IntroducciÃ³n teÃ³rica** | - Â¿QuÃ© es un LLM? <br> - Â¿CÃ³mo funciona un Transformer? <br> - Aplicaciones en anÃ¡lisis de datos <br> - QuÃ© es un *prompt* y cÃ³mo diseÃ±arlo correctamente | PresentaciÃ³n con visuales + ejemplos en vivo |
| **0:30 - 1:00** | ğŸ§ª **Ejercicio 1 â€“ Buenas prÃ¡cticas con prompts** | - Subida de `consumo_diario.csv` <br> - Comparativa entre prompts vagos vs estructurados <br> - Extraer estructura del dataset y detectar valores nulos | ChatGPT o Gemini |
| **1:00 - 1:30** | ğŸ§ª **Ejercicio 2 â€“ AnÃ¡lisis exploratorio automÃ¡tico** | - Pedir resÃºmenes y estadÃ­sticas bÃ¡sicas al modelo <br> - Generar un grÃ¡fico simple desde lenguaje natural <br> - Interpretar y corregir salidas del modelo | ChatGPT o Gemini |
| **1:30 - 2:15** | ğŸ§ª **Ejercicio 3 â€“ GeneraciÃ³n de cÃ³digo con un LLM** | - Solicitar cÃ³digo Python (Pandas + Matplotlib) desde un prompt <br> - Ejecutar el cÃ³digo en VSCode <br> - Verificar funcionamiento y modificar visualizaciÃ³n | ChatGPT + VSCode |
| **2:15 - 2:45** | ğŸ§ª **Ejercicio 4 â€“ DetecciÃ³n de anomalÃ­as en series temporales** | - Pedir al LLM que detecte outliers <br> - Visualizar puntos anÃ³malos en rojo <br> - Generar y analizar el cÃ³digo subyacente | ChatGPT + VSCode |
| **2:45 - 3:00** | ğŸ’¬ **Cierre y reflexiÃ³n + explicaciÃ³n de la tarea** | - DiscusiÃ³n sobre fortalezas y limitaciones de los LLMs <br> - Consejos para seguir explorando en casa <br> - Entrega de la tarea autÃ³noma: analizar un dataset propio | Debate abierto + instrucciones escritas |

---

### ğŸ  Tarea para casa (1.5h)

> **TÃ­tulo:** Explorando tu propio dataset con un modelo de lenguaje

**DescripciÃ³n:**  
El alumnado seleccionarÃ¡ o reutilizarÃ¡ un dataset sencillo (agua, energÃ­a, temperatura, etc.) y realizarÃ¡:
- Un anÃ¡lisis descriptivo con prompts en ChatGPT o Gemini.
- Un intento de detecciÃ³n de valores anÃ³malos.
- Una visualizaciÃ³n generada con ayuda del modelo.

**Entrega:** Captura de pantalla de los resultados + breve reflexiÃ³n (mÃ¡x. 300 palabras)

---

## ğŸ“… SesiÃ³n 2 (3h): Consulta y anÃ¡lisis de datos con herramientas LLM

**DuraciÃ³n:** 3h lectivas + 1.5h de trabajo autÃ³nomo  
**Objetivo:** Explorar y comparar herramientas que permiten interactuar con datasets mediante lenguaje natural, sin necesidad de conocimientos avanzados de programaciÃ³n.

### Parte teÃ³rica (30 minutos)

- Â¿QuÃ© son los LLM agents aplicados a datos?
- Â¿QuÃ© ventajas ofrecen frente a cÃ³digo tradicional?
- Diferencias entre asistentes conversacionales (Claude, ChatGPT) y agentes integrados en herramientas (Copilot, LangChain).
- PresentaciÃ³n de herramientas seleccionadas:
  - Claude Artifacts
  - Julius AI
  - GitHub Copilot en Notebooks
  - LangChain Tabular Agent
- Comparativa de sus capacidades: tipo de interacciÃ³n, trazabilidad, requisitos tÃ©cnicos, contexto ideal.

---

### Ejercicio 1 â€“ *Claude Artifacts para anÃ¡lisis sin cÃ³digo*
- Cargar CSV y realizar preguntas sobre consumo y temperatura.
- Generar artefactos visuales reutilizables.
- Explorar patrones y generar informes automÃ¡ticos.

### Ejercicio 2 â€“ *ExploraciÃ³n de datos con Julius AI*
- AnÃ¡lisis de un CSV multivariable sin cÃ³digo ni instalaciÃ³n.
- Preguntas creativas sobre consumo, condiciones ambientales y relaciones.
- ComparaciÃ³n con Claude.

### Ejercicio 3 â€“ *AnÃ¡lisis asistido con GitHub Copilot en VSCode*
- Escribir comentarios en celdas que Copilot convierte en cÃ³digo Python.
- GrÃ¡ficos, estadÃ­sticas y explicaciÃ³n automÃ¡tica del cÃ³digo.
- Uso de `m6_consumo_agua.csv`.

### Ejercicio 4 â€“ *Agente inteligente para anÃ¡lisis multivariable con LangChain Tabular Agent*
- Crear un agente con GPT-4 y conectar un DataFrame multivariable.
- Consultas como â€œdÃ­as con mayor ratio agua/energÃ­aâ€ o â€œdetecciÃ³n de valores faltantesâ€.
- Comparativa entre herramientas.

---

### Desglose esquemÃ¡tico â€“ MÃ³dulo 6, SesiÃ³n 2

| Tiempo        | Actividad                                       | Herramienta               |
|---------------|--------------------------------------------------|----------------------------|
| 0:00 â€“ 0:30   | IntroducciÃ³n y repaso teÃ³rico                   | PresentaciÃ³n + demostraciÃ³n |
| 0:30 â€“ 1:05   | Claude Artifacts: exploraciÃ³n sin cÃ³digo        | Claude.ai                  |
| 1:05 â€“ 1:40   | Julius AI: visualizaciÃ³n y resÃºmenes            | Julius.ai                  |
| 1:40 â€“ 2:15   | GitHub Copilot en Jupyter                       | VSCode + Copilot           |
| 2:15 â€“ 2:50   | LangChain Tabular Agent (avanzado)              | LangChain + GPT-4          |
| 2:50 â€“ 3:00   | Cierre y explicaciÃ³n de la tarea                | Debate abierto             |

---

### ğŸ  Tarea para casa (1.5h)

#### **TÃ­tulo:** Compara dos herramientas conversacionales para anÃ¡lisis de datos

**DescripciÃ³n:**  
El alumnado debe elegir dos de las herramientas vistas en clase (Claude, Julius AI, Copilot o LangChain) y realizar las siguientes tareas:

- Cargar un nuevo dataset (puede ser una versiÃ³n reducida del que trabajamos en clase).
- Hacer al menos **3 preguntas analÃ­ticas** en lenguaje natural.
- **Comparar los resultados, explicaciones y facilidad de uso.**
- Incluir al menos una visualizaciÃ³n generada por cada herramienta.

**Formato de entrega:**  
- PDF o `.ipynb` con capturas, resultados y reflexiÃ³n breve (mÃ¡x. 400 palabras).

---

### Resultados esperados

Al finalizar esta sesiÃ³n, el profesorado serÃ¡ capaz de:

- Comprender los distintos enfoques para consultar datos con LLMs.
- Utilizar asistentes como Copilot o Claude para analizar datos sin conocimientos profundos de cÃ³digo.
- Evaluar el potencial de herramientas como LangChain para proyectos educativos mÃ¡s avanzados.
- Comparar herramientas segÃºn facilidad, transparencia y aplicabilidad.
- Reflexionar sobre el uso de IA conversacional en el aula y proyectos docentes.
